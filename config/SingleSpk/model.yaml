transformer:
  encoder_layer: 4
  encoder_head: 2
  encoder_hidden: 256
  decoder_layer: 6
  decoder_head: 2
  decoder_hidden: 256
  conv_filter_size: 1024
  conv_kernel_size: [9, 1]
  encoder_dropout: 0.1
  decoder_dropout: 0.15


variance_predictor:
  filter_size: [256, 384, 256]
  kernel_size: [3, 3, 4]
  dropout: 0.25
  dropout_on_emb: 0.5 # dropout applied to pitch&energy embs before adding to decoder input, doesn't affect predictors directly

duration_predictor:
  type: "tcn" # support tcn (TCN-Attention) or lstm (Conv+Decoder+LSTM)
  bidirectional: true # both: bidirectional
  att_dropout: 0.25 # only applies to TCN duration pred, dropout applied to attention
  tcn_channels: [384, 512 , 256] # only applies to TCN duration pred
  tcn_heads: [2, 4, 2] #tcn: attention heads for each layer. you can use 0 to disable multi-head and use squeeze-excite
  tcn_kernel_sizes: [2, 3, 3] #tcn: kernel sizes for each layer
  backwards_tcn_channels: [256, 256]
  backwards_heads: [2, 2]
  backwards_kernel_sizes: [2, 3]
  decoder_depth: 2 # lstm: depth of auxiliary decoder
  conv_depth: 2 # lstm: depth of pre-convs
  kernel_size: 3 # lstm: conv kernel size
  heads: 2 # lstm: attention heads
  filter_size: 256 # lstm: hidden size
  dropout: 0.15 # both: dropout



variance_embedding:
  pitch_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the pitch values are not normalized during preprocessing
  energy_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the energy values are not normalized during preprocessing
  n_bins: 256

# gst:
#   use_gst: False
#   conv_filters: [32, 32, 64, 64, 128, 128]
#   gru_hidden: 128
#   token_size: 128
#   n_style_token: 10
#   attn_head: 4

multi_speaker: False
max_seq_len: 1000

vocoder:
  model: "iSTFTNet" # support 'HiFi-GAN', 'MelGAN'
  speaker: "LJSpeech" # support  'LJSpeech', 'universal'
